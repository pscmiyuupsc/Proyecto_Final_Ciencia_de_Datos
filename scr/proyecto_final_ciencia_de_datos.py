# -*- coding: utf-8 -*-
"""Proyecto_Final_Ciencia_de_Datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xjOEUsa1KPezyp8OePxjzdd-VpQs6h9-

# **Proyecto Final Ciencia De Datos: Modelos predictivos para la afluencia en el Metrobús de la CDMX**
*Sarmiento Escobar Millaray*

#Librerias utilizadas
"""

#Librerias utilizadas

#Drive
from google.colab import drive
from google.colab import files
#Dataframe
import pandas as pd
import chardet
import numpy as np


#Visualizacion
import matplotlib.pyplot as plt
import seaborn as sns

#Utilizados en la creacion del mapa que muestra la afluencia
import zipfile
import os
import geopandas as gpd
import folium
from shapely.geometry import LineString

#Autocorrelacion
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

#Fechas
import matplotlib.dates as mdates
from datetime import datetime, timedelta

#Busqueda de hiperparametros
from sklearn.model_selection import RandomizedSearchCV

#Modelo
import xgboost as xgb
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import TimeSeriesSplit

#Metricas
from sklearn.metrics import mean_absolute_error, mean_squared_error

"""# IMPORTACION DE LOS DATOS"""

#Drive
#drive.mount('/content/drive')

"""En Python existe una librería llamada chardet que permite leer una muestra del archivo y detectar la codificación de un archivo en python, esto lo hace mediante secuencias de bytes y nos muestra el nivel de confianza de que la base sea de cierta codificación."""

#Se creo la variable path(ruta) y se definio la ruta del archivo
#path = "/content/drive/My Drive/Ciencia de datos/Proyecto final/baseafluencia/afluencia.csv"
#Se abre el archivo con un modo de lectura binaria, por lo que los datos se leen como bytes sin interpretar
#with open(path, "rb") as p:

# f.read() se leerán todos los bytes del archivo, (no recomendable para archivos grandes)
#Usualmente verán que esta parte se llama "rawdata" porque es tomado como datos crudos ya que chardet analiza los bytes no procesados
 #   rawdata = p.read(5000)

#Ahora usando la función detect se devolverá un diccionario de 3 variables:
#Codificación,  Confianza y  Language
#result = chardet.detect(rawdata)
#result

"""Para esta base de datos se ontuvo una codificacion utf-8"""

# Lectura del archivo
#df=pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/baseafluencia/afluencia.csv")
df=pd.read_csv("afluencia.csv",encoding="utf-8")

#Se muestran los primeros 5 datos
df.head(5)

#Se muestran los ultimos 5 datos
df.tail(5)

"""# PREPROCESAMIENTO DE LOS DATOS"""

#Informacion del df
df.info()

"""Se observa que no hay valores nulos

**object**


Tipo general que puede contener cualquier tipo de dato, incluyendo cadenas, números, fechas, etc.
"""

#Forma del df
df.shape

"""En este caso nuestro df tiene una forma de (484,8) en este caso se refiere a que son 484 filas y 8 columnas"""

#Funcion para procesar y agrupar la afluencia
def procesar_afluencia(df):
#Se crea una columna llamada afluencia_total
#Se agrupa en base a la fecha y la linea
#Se suma y transforma lo anterior para tener tamaño igual al df original
    df['afluencia_total'] = df.groupby(['fecha', 'linea'])['afluencia'].transform('sum')

#Se crea un nuevo df y se agrupa de la misma manera, en donde solo se toma el
#primer valor y se resetea en indice
    df_nuevo = df.groupby(['fecha', 'linea']).first().reset_index()

   # Eliminamos las columnas afluencia(ya que ya se tiene la afluencia total) y el tipo de pago y ..anio_fecha debido a la redundancia con anio
    columnas_a_eliminar = ['afluencia', 'tipo_pago']
    df_nuevo = df_nuevo.drop(columns=columnas_a_eliminar, errors='ignore')

    return df_nuevo

#Df con la afluencia procesada(suma de la forma de pago (prepago y gratuidad))
df_nuevo = procesar_afluencia(df)
print(df_nuevo.head())

#Se elimina el dia bisiesto para que la implementacion en 2025 la longitud sea la misma
indices= df_nuevo[df_nuevo['fecha'] == '2024-02-29'].index
print(indices)
df_nuevo = df_nuevo.drop(indices).reset_index(drop=True)

#Forma del df
df_nuevo.shape

"""Nuestro df nuevo tiene una forma de **(240,7)** en este caso se refiere a que son 240 filas y 7 columnas"""

#columnas del nuevo df
print(df_nuevo.columns)

df_nuevo.info() #informmacion sobre el tipo de datos y si hay existencia de valores nulos

"""confiemamos que no hay existencia de valores nulos y por tanto damos lugar al EDA"""

# Se crea un filtro por linea en base al nuevo df de los datos para las líneas 1 y 2
df_linea1 = df_nuevo[df_nuevo['linea'] == 'Línea 1']
df_linea2 = df_nuevo[df_nuevo['linea'] == 'Línea 2']

# Se agrega las variable de clima (incluye temperatura del aire, precipitacion,humedad especifica y humedad relativa)
#datos_clima=pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/climacdmx/clima.csv")
datos_clima=pd.read_csv("clima.csv")

#Primeros 5 datos del clima
datos_clima.head()

#UNION DE LOS DF
#Resetea el indice de cada set
df_linea1 = df_linea1.reset_index(drop=True)
datos_clima = datos_clima.reset_index(drop=True)

# Une solo las columnas de clima por el índice
df_linea1 = df_linea1.join(datos_clima[['temp_aire_celsius', 'precipitacion', 'humedad_especifica', 'humedad_relativa']])

#Primeros 5 datos y ultimos 5 datos
df_linea1.head()

#UNION DE LOS DF
#Resetea el indice de cada set
df_linea2 = df_linea2.reset_index(drop=True)
datos_clima = datos_clima.reset_index(drop=True)

# Une solo las columnas de clima por el índice
df_linea2 = df_linea2.join(datos_clima[['temp_aire_celsius', 'precipitacion', 'humedad_especifica', 'humedad_relativa']])

df_linea2

"""# ANALISIS EXPLORATORIO DE LOS DATOS"""

#Iniciaremos viendo si tenemos la misma cantidad de datos para la linea 1 y para la linea 2
#Conteo de los datos por linea
conteo=df_nuevo["linea"].value_counts()
print("Cantidad de datos por linea")
print(conteo)

# Diccionario para cada una de las lineas
colores_lineas = {'Línea 1': '#FF6666', 'Línea 2': 'purple'}

#visualizacion de cantidad de datos por linea
plt.figure(figsize=(10,6))
conteo.plot(kind="bar",color=colores_lineas.values())
plt.title("Cantidad de datos por linea")
plt.xlabel("Linea")
plt.ylabel("Datos")
plt.show()

# Gráfico de líneas (1 y 2)
plt.figure(figsize=(10, 6))
plt.plot(df_linea1['fecha'], df_linea1['afluencia_total'], label='Línea 1',color="#FF6666")
plt.plot(df_linea2['fecha'], df_linea2['afluencia_total'], label='Línea 2',color="purple")

# Configuracion el gráfico
plt.title('Afluencia en el metrobus linea 1 y 2 (febrero-mayo 2024)')#titulo
plt.ylabel('Personas por linea')#etiqueta del eje y
plt.xlabel('Afluencia de febrero a mayo 2024')#etiqueta del eje x
plt.xticks([])  #Se elimina todas las etiquetas del eje X
plt.legend()  # Muestra la leyenda para distinguir entre líneas
plt.tight_layout()  # Ajusta el espacio entre elementos del gráfico
plt.show()#Muestra el grafico

# Orden en base al mes (febrero a mayo 2024)
df_mes = df_nuevo.groupby(['mes', 'linea'], as_index=False)['afluencia_total'].sum()
orden_meses = ['Febrero', 'Marzo', 'Abril', 'Mayo']
df_mes['mes'] = pd.Categorical(df_mes['mes'], categories=orden_meses, ordered=True)

# Df para cada una de las lineas
df_linea1_af = df_mes[df_mes['linea'] == 'Línea 1'].sort_values('mes')
df_linea2_af = df_mes[df_mes['linea'] == 'Línea 2'].sort_values('mes')



# Tamaño del grafico
plt.figure(figsize=(10, 6))

# Orden de los meses para eje x
x = range(len(orden_meses))  # Posiciones 0,1,2,3 correspondientes a los meses

# Linea 1
plt.plot(x, df_linea1_af['afluencia_total'],
         label='Línea 1', #Etiqueta
         color=colores_lineas['Línea 1'], #Color rojo para la linea 1
         marker='o',#Circulo  en el mes correspondiente
         linewidth=2)#Grosor de la linea

# Linea 2
plt.plot(x, df_linea2_af['afluencia_total'],
         label='Línea 2',#Etiqueta
         color=colores_lineas['Línea 2'],  #Color rojo para la linea 2
         marker='o',#Circulo  en el mes correspondiente
         linewidth=2)#Grosor de la linea

# Etiquetas para mostrar  la afluencia por mes
for i, val in enumerate(df_linea1_af['afluencia_total']):
    plt.text(i, val + 5000, f"{val:,}", ha='center', va='bottom', fontsize=9)

for i, val in enumerate(df_linea2_af['afluencia_total']):
    plt.text(i, val + 5000, f"{val:,}", ha='center', va='bottom', fontsize=9)

# Configuración del gráfico
plt.title('Afluencia por mes linea 1 y 2 del metrobus (febrero-mayo 2024)')
plt.xlabel('Mes')
plt.ylabel('Afluencia Total')
plt.xticks(x, orden_meses)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()

# Mostrar
plt.show()

"""En terminos generales y antes de entrar a los estadisticos descriptivos podemos observar que a lo largo de los meses de febrero a mayo del 2024 la afluencia en la linea 1 es mayor(aproximadamente el doble) que en la linea 2 y que existe un aumento en el mes de mayo en ambas lineas"""

#Descriptivos en base a la linea
descriptivos = df_nuevo.groupby('linea')['afluencia_total'].describe()
descriptivos

# Caja de bigotes para ver la afluencia por linea
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_nuevo, x='linea', y='afluencia_total', hue='linea', palette=['#FF6666', 'purple'], legend=False)

# Configuracion del gráfico
plt.title("Afluencia en el metrobus linea 1 y 2 (febrero-mayo 2024)")
plt.xlabel("lineas del mb")
plt.ylabel('Numero de personas por linea')
plt.show()

"""Para la **linea 1** encontramos un media de **411,522** y una mediana de **473,268**, con valores mas cercanos al tercer cuartil **496,831** lo que nos indica un sesgo a la izquierda, indicando que pueden existir mayor concentracion de datos a la derecha, tambien tenemos una desviacion estandar de **112,963** lo cual se puede interpretar como una variablidad general considerable entre los datos


Para la **linea 2** encontramos un media de **217,151** y una mediana de **245,044**, con valores mas cercanos al tercer cuartil **261,791** lo que nos indica un sesgo a la izquierda, indicando que pueden existir mayor concentracion de datos a la derecha, tambien tenemos una desviacion estandar de **57,458** lo cual se puede interpretar como una variablidad general considerable entre los datos





"""

#MAPA DE CALOR PARA LA LINEA 1 DEL METROBUS DE LA CDMX
# Selecciona de columnas
columnas_numericas = df_linea1.select_dtypes(include=['int64', 'float64'])
# Eliminacion de la columna anio, debido a que solo muestra el año de los datos(es decir 2024)
columnas_numericas= columnas_numericas.drop(columns=['anio',"..anio_fecha"], errors='ignore')  # 'errors='ignore'' evita errores si la columna no existe

# Calcula la matriz de correlación
corr_matrix = columnas_numericas.corr()

# Visualiza la matriz de correlación

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title("Mapa de calor para la linea 1 del metrobus")
plt.show()

"""Encontramos una correlacion baja entre la afluencia total y las variables climatologicas para la linea 1 del metrobus de la cdmx"""

#MAPA DE CALOR PARA LA LINEA 2 DEL METROBUS DE LA CDMX
# Selecciona de columnas tipo int and float
columnas_numericas = df_linea2.select_dtypes(include=['int64', 'float64'])
# Eliminacion de la columna anio, debido a que solo muestra el año de los datos(es decir 2024)
columnas_numericas= columnas_numericas.drop(columns=['anio',"..anio_fecha"], errors='ignore')  # 'errors='ignore'' evita errores si la columna no existe

# Calcula la matriz de correlación
corr_matrix = columnas_numericas.corr()

# Visualiza la matriz de correlación

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title("Mapa de calor para la linea 2 del metrobus")
plt.show()

"""Encontramos una correlacion baja entre la afluencia total y las variables climatologicas para la linea 2 del metrobus de la cdmx

#SECCIONAMIENTO DE LOS DATOS/INGENIERIA DE LAS CARACTERISTICAS
"""

#traformacion de object a .dt
df['fecha'] = pd.to_datetime(df['fecha'])
df_nuevo['fecha'] = pd.to_datetime(df_nuevo['fecha'])
df_linea1['fecha'] = pd.to_datetime(df_linea1['fecha'])
df_linea2['fecha'] = pd.to_datetime(df_linea2['fecha'])

# Funcion para clasificar el tipo de dia
def dias_xgboost(df, year=2024):
    # Columna tipo_dia con valores por defecto
    df['tipo_dia'] = np.where(df['fecha'].dt.dayofweek < 5, 'Entre Semana', 'Fin de Semana')

    # Feriados del 2024 y 2025
    feriados = pd.to_datetime(['2024-02-05', '2024-03-18', '2024-05-01']) if year == 2024 else \
               pd.to_datetime(['2025-02-03', '2025-03-17', '2025-05-01'])

    # Dia feriado aplicado para que se pueda distinguir
    df.loc[df['fecha'].isin(feriados), 'tipo_dia'] = 'Feriado'

    # Extraer características de dia de la semana y del mes
    df['dia_semana'] = df['fecha'].dt.dayofweek  #Se ve representado el dia de la semana de 0 a 6 donde 0 es lunes y asi sucesivamente
    df['dia_mes'] = df['fecha'].dt.day

    # Uso de dummies
    dummies = pd.get_dummies(df['tipo_dia'], prefix='tipo_dia')

    # Concatenar dummies y eliminar columna original
    df_final = pd.concat([df.drop(columns=['tipo_dia']), dummies], axis=1)

    return df_final

# Aplicacion la función a cada df
df_linea1 = dias_xgboost(df_linea1, year=2024).reset_index(drop=True)
df_linea2= dias_xgboost(df_linea2, year=2024).reset_index(drop=True)

"""Aplicacion de one hot encoding para tipo_dia y para dia_semana y dia_mes se le extrajo el dia y el mes respectivamente"""

#Df con los tipos de dia para la linea 1
df_linea1.head()

#Df con los tipos de dia para la linea 2
df_linea2.head()

#Columnas
print(df_linea1.columns)
print(df_linea2.columns)

#Frecuencia de tipo de dia para la linea 1
frecuencias_tipo_dia_linea1 = {
    'Entre Semana': df_linea1['tipo_dia_Entre Semana'].sum(),
    'Feriado': df_linea1['tipo_dia_Feriado'].sum(),
    'Fin de Semana': df_linea1['tipo_dia_Fin de Semana'].sum()
}

print("Frecuencia por cada tipo de dia df_linea1:")
for tipo, freq in frecuencias_tipo_dia_linea1.items():
    print(f"{tipo}: {int(freq)}")

#Frecuencia de tipo de dia para la linea 2
frecuencias_tipo_dia_linea2 = {
    'Entre Semana': df_linea2['tipo_dia_Entre Semana'].sum(),
    'Feriado': df_linea2['tipo_dia_Feriado'].sum(),
    'Fin de Semana': df_linea2['tipo_dia_Fin de Semana'].sum()
}

print("Frecuencia por cada tipo de dia df_linea2:")
for tipo, freq in frecuencias_tipo_dia_linea2.items():
    print(f"{tipo}: {int(freq)}")

#funcion para graficas de frecuencia en base al tipo de dia

def grafica_frecuencia(df, nombre_df):
    # Suma cada columna para observar la frecuencia
    frecuencias = {
        'Entre Semana': df['tipo_dia_Entre Semana'].sum(),
        'Fin de Semana': df['tipo_dia_Fin de Semana'].sum(),
        'Feriado': df['tipo_dia_Feriado'].sum()

    }

    # Se convierten en series para que sea mas sencillo graficar
    frecuencias_series = pd.Series(frecuencias)

    # Grafica
    plt.figure(figsize=(8, 6))
    frecuencias_series.plot(kind='bar', color=plt.cm.Set3(np.linspace(0, 1, len(frecuencias_series))))
    plt.title(f"Frecuencia por Tipo de Día en {nombre_df}")
    plt.xlabel("Tipo de Día")
    plt.ylabel("Frecuencia")
    plt.xticks(rotation=0)
    plt.show()

grafica_frecuencia(df_linea1, "en la linea 1")

grafica_frecuencia(df_linea2, "la linea 2 ")

#Funcion para ver la afluencia en base al tipo de dia
def grafica_afluencia_simple(df, nombre_df):
    # Elegimos las columnas para ver la afluencia en base al tipo de dia
    cols_tipo = ['tipo_dia_Entre Semana', 'tipo_dia_Fin de Semana','tipo_dia_Feriado']

    # Transformar columnas dummy
    df_melt = pd.melt(df, id_vars=['afluencia_total'], value_vars=cols_tipo,
                      var_name='tipo_dia', value_name='es_tipo')

    # Filtrar filas
    df_melt = df_melt[df_melt['es_tipo'] == 1].copy()

    # Limpiar nombres de tipo_dia para que sean legibles
    df_melt['tipo_dia'] = df_melt['tipo_dia'].str.replace('tipo_dia_', '')

    # Graficar boxplot
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='tipo_dia', y='afluencia_total', data=df_melt, hue='tipo_dia', palette='Set2', showfliers=False,legend=False)
    plt.title(f"Afluencia por tipo de día en {nombre_df}")
    plt.xlabel("Tipo de Día")
    plt.ylabel("Afluencia Total")
    plt.show()

grafica_afluencia_simple(df_linea1, "Línea 1")

grafica_afluencia_simple(df_linea2, "Línea 2")

def estadisticos_tipo_dia(df, nombre_linea):


    print(f"Estadísticos por tipo de día - {nombre_linea}")

    # Columna categorica temporal combinando las dummies
    condiciones = [
        df['tipo_dia_Entre Semana'] == 1,
        df['tipo_dia_Fin de Semana'] == 1,
        df['tipo_dia_Feriado'] == 1
    ]
    opciones = ['Entre Semana', 'Fin de Semana', 'Feriado']

    df['tipo_dia'] = np.select(condiciones, opciones, default='Otro')

    # 2. Calcular estadísticos con describe()
    estadisticos = df.groupby('tipo_dia')['afluencia_total'].describe()

    # 4. Eliminar columna temporal (opcional)
    df.drop('tipo_dia', axis=1, inplace=True)

    return estadisticos

estadisticos_tipo_dia(df_linea1, "Línea 1")

"""**AFLUENCIA DE LA LINEA 1 DEL METROBUS**

**Dias entre semana**

El promedio es de 477,681, la mediana es de 490,198 y la desviación estándar es de 48,563 , el valor mínimo 212,350 y el máximo 528,289 lo que sugiere que durante los días entre semana hay una alta actividad en comparacion a los demas tipos de dias,con respecto a la desviacion estandar se ve algo de variabilidad pero sin ser extremo

**Feriado**

El promedio es de 222,502, la mediana es de 218,310 y la desviación estándar es de	21,339, el valor mínimo 203,570 y el máximo 245,627, lo que sugiere que los dias festivos tienen una actividad estable sin embargo al ser pocos datos la informacion puede verse



**Fin de semana**

El promedio es de 264,747, la mediana es de 240,338,la desviación estándar es de 62,113, el valor mínimo 176,589 y el máximo 389,015  lo que sugiere que existe una variabilidad moderada y la existencia de sesgo hacia valores mas altos


"""

estadisticos_tipo_dia(df_linea2, "Línea 2")

"""**AFLUENCIA DE LA LINEA 2 DEL METROBUS**

**Dias entre semana**
El promedio es de 249,341, la mediana es de 255,465, la desviación estándar es de 28,947, el valor mínimo es 105,543 y el máximo es 293,031.
Esto sugiere que, aunque el uso promedio es alto, hay días de la semana con una afluencia significativamente menor.



**Fin de semana**
El promedio es de 145,554, la mediana es de 134,194, la desviación estándar es de 35,224, el valor mínimo es 98,966 y el máximo es 216,214.

**Feriado**
 El promedio es de 127,291, la mediana es de 124,997, la desviación estándar es de 7,780, el valor mínimo es 120,915 y el máximo es 135,960,lo que indica una variabilidad moderada.

RECUERDA AL FINAL ADJUNTAR LOS ARCHIVOS QUE USASTE EN TU DRIVE LA CARPETA SE LLAMA datosgeograficos y ahi viene el archivo que debes adjuntar

#RUTA ZIP Y GEOJSON DE LA LINEA 1 Y 2 DEL MB DE LA CDMX
"""

#Se asigna la ruta zip donde tenemos los datos geograficos
#ruta_zip = "/content/drive/My Drive/Ciencia de datos/Proyecto final/datosgeograficos/datosgeomblinea1y2.zip"
ruta_zip= "datosgeomblinea1y2.zip"

#ruta_zip = "/content/drive/My Drive/Ciencia de datos/Proyecto final/datosgeograficos/datosgeomblinea1y2.zip" #ruta donde estan los datos
ruta_destino = "/content/datos_geojson"

# Carpeta destino
os.makedirs(ruta_destino, exist_ok=True)

# Extraer ZIP
with zipfile.ZipFile(ruta_zip, 'r') as zip_ref:
    zip_ref.extractall(ruta_destino)

#Verificar si estan los archivos
print(os.listdir(ruta_destino))

#Funcion para poder cargar los archivos
def cargar_datos_geojson(ruta_base="/content/datos_geojson"):
    archivo_estaciones = os.path.join(ruta_base, "Metrobus_estaciones.json")
    archivo_lineas = os.path.join(ruta_base, "Metrobus_lineas.json")

    if not os.path.exists(archivo_estaciones):
        raise FileNotFoundError(f"No se encontró: {archivo_estaciones}")
    if not os.path.exists(archivo_lineas):
        raise FileNotFoundError(f"No se encontró: {archivo_lineas}")

    estaciones = gpd.read_file(archivo_estaciones)
    lineas = gpd.read_file(archivo_lineas)
    return estaciones, lineas

# Cargar los archivos
estacionesmblinea1y2, lineasmb1y2 = cargar_datos_geojson()

#Primeros 5 datos de las estaciones
print(estacionesmblinea1y2.head())

#Primeros 5 datos de las lineas
print(lineasmb1y2.head())

#Columnas de las estaciones y de las columnas
print(estacionesmblinea1y2.columns)
print(lineasmb1y2.columns)

"""

#MAPA DE LA CDMX CON LINEA 1 Y 2 DEL MB"""

#Estaciones de cada linea
print("Estaciones Línea 1:", estacionesmblinea1y2[estacionesmblinea1y2['LINEA'] == '01']['NOMBRE'].unique())#Estaciones de la linea 1
print("Estaciones Línea 2:", estacionesmblinea1y2[estacionesmblinea1y2['LINEA'] == '02']['NOMBRE'].unique()) #Estaciones de la linea 2

#Columnas de las estaciones,
print("Columnas de estacionesmblinea1y2:", estacionesmblinea1y2.columns.tolist())
print("Columnas de df_nuevo:", df_nuevo.columns.tolist())

#MAPA COMPLETO CON LAS ESTACIONES

#Estaciones por linea
estaciones_por_linea = {
   '01': ["Indios Verdes","Dep. 18 de Marzo","Eúzkaro","Potrero","La Raza","Circuito","San Simón",
           "Manuel González","Buenavista","El Chopo","Revolución","Plaza de la República","Reforma","Hamburgo",
           "Insurgentes","Durango","Álvaro Obregón","Sonora","Campeche","Chilpancingo","Nuevo León","La Piedad",
           "Polifórum","Nápoles","Colonia del Valle","Ciudad de los Deportes","Parque Hundido","Félix Cuevas",
           "Río Churubusco","Teatro de los Insurgentes","José María Velasco","Francia","Olivo","Altavista","La Bombilla",
           "Doctor Gálvez","Ciudad Universitaria","C.C.U.","Perisur","Villa Olímpica","Corregidora","Ayuntamiento",
           "Fuentes Brotantes","Santa Úrsula","La Joya","El Caminero"],
     '02': ["Tacubaya","Parque Lira" "Antonio Maceo", "De la Salle", "Patriotismo", "Escandón", "Nuevo León", "Viaducto",
            "Amores", "Etiopía", "Doctor Vértiz", "Centro SCOP", "Álamos", "Xola", "Las Américas",
            "Andrés Molina Enríquez", "La Viga", "Coyuya", "Metro Coyuya", "Canela", "Tlacotal", "Goma", "Iztacalco",
            "UPIICSA", "El Rodeo", "Río Tecolutla","Río Mayo","Rojo Gómez", "Río Frío","Leyes de Reforma", 'Del Moral',
            "CCH Oriente", "Const. de Apatzingán", "Gral. Antonio de León", "Canal de San Juan", "Nicolás Bravo",
            "Tepalcates"]}


# Función para crear líneas desde estaciones
def crear_linea_desde_estaciones(linea):
    coords = []
    for nombre_estacion in estaciones_por_linea[linea]:
        estacion = estacionesmblinea1y2[estacionesmblinea1y2['NOMBRE'] == nombre_estacion.strip()]
        if not estacion.empty:
            coords.append((estacion.iloc[0].geometry.x, estacion.iloc[0].geometry.y))
    return LineString(coords) if coords else None

# Mapa base
m = folium.Map(location=[19.4326, -99.1332], zoom_start=12)

# Configuracion de los colores
colores = {'01': 'red', '02': 'purple'}

# Añadir líneas directamente al mapa (sin capas separadas)
for linea in ['01', '02']:
    linea_geom = crear_linea_desde_estaciones(linea)
    if linea_geom:
        folium.GeoJson(
            gpd.GeoSeries([linea_geom]).to_json(),
            style_function=lambda x, c=colores[linea]: {
                'color': c,
                'weight': 3,  # Grosor
                'opacity': 0.8
            }
        ).add_to(m)

# Añadir todas las estaciones
for linea in ['01', '02']:
    for nombre in estaciones_por_linea[linea]:
        estacion = estacionesmblinea1y2[estacionesmblinea1y2['NOMBRE'] == nombre.strip()]
        if not estacion.empty:
            folium.CircleMarker(
                location=[estacion.iloc[0].geometry.y, estacion.iloc[0].geometry.x],
                radius=5,
                color=colores[linea],
                fill=True,
                popup=f"{nombre} (Línea {linea})"
            ).add_to(m)

m  # Mapa
#m.save("mapa_lineas_1y2.html")
#files.download("mapa_lineas_1y2.html")

# Mapa de la CDMX en las coordenadas
m = folium.Map(location=[19.4326, -99.1332], zoom_start=12)

# Estaciones por linea
estaciones_por_linea = {
    '01': ["Indios Verdes","Dep. 18 de Marzo","Eúzkaro","Potrero","La Raza","Circuito","San Simón",
           "Manuel González","Buenavista","El Chopo","Revolución","Plaza de la República","Reforma","Hamburgo",
           "Insurgentes","Durango","Álvaro Obregón","Sonora","Campeche","Chilpancingo","Nuevo León","La Piedad",
           "Polifórum","Nápoles","Colonia del Valle","Ciudad de los Deportes","Parque Hundido","Félix Cuevas",
           "Río Churubusco","Teatro de los Insurgentes","José María Velasco","Francia","Olivo","Altavista","La Bombilla",
           "Doctor Gálvez","Ciudad Universitaria","C.C.U.","Perisur","Villa Olímpica","Corregidora","Ayuntamiento",
           "Fuentes Brotantes","Santa Úrsula","La Joya","El Caminero"],
     '02': ["Tacubaya","Parque Lira" "Antonio Maceo", "De la Salle", "Patriotismo", "Escandón", "Nuevo León", "Viaducto",
            "Amores", "Etiopía", "Doctor Vértiz", "Centro SCOP", "Álamos", "Xola", "Las Américas",
            "Andrés Molina Enríquez", "La Viga", "Coyuya", "Metro Coyuya", "Canela", "Tlacotal", "Goma", "Iztacalco",
            "UPIICSA", "El Rodeo", "Río Tecolutla","Río Mayo","Rojo Gómez", "Río Frío", "Leyes de Reforma", 'Del Moral',
            "CCH Oriente", "Const. de Apatzingán", "Gral. Antonio de León", "Canal de San Juan", "Nicolás Bravo",
            "Tepalcates"]}

# 3. Función para crear lineas a partir de las estaciones
def crear_linea_desde_estaciones(linea):
    coords = []
    for nombre_estacion in estaciones_por_linea[linea]:
        estacion = estacionesmblinea1y2[estacionesmblinea1y2['NOMBRE'] == nombre_estacion]
        if not estacion.empty:
            coords.append((estacion.iloc[0].geometry.x, estacion.iloc[0].geometry.y))
    return LineString(coords) if coords else None

# Se ponen los meses en orden
meses = ['Febrero', 'Marzo', 'Abril', 'Mayo']

for mes in meses:
    # Capa por cada mes
    capa_mes = folium.FeatureGroup(name=f'Afluencia 2024 {mes}', show=(mes=='Febrero'))

    # Geometria por linea
    for linea in ['01', '02']:
        linea_geom = crear_linea_desde_estaciones(linea)
        if not linea_geom:
            continue

        # Afluencia por mes para cada una de las lineas
        if linea == '01':
            afluencia = df_linea1_af[df_linea1_af['mes'] == mes]['afluencia_total'].values[0]
        else:
            afluencia = df_linea2_af[df_linea2_af['mes'] == mes]['afluencia_total'].values[0]

        # Grosor para las lineas
        grosor_base = 2 if linea == '01' else 1  #Ajuste del grosor debido a que los datos son diferentes en cantidad de afluencia
        weight = grosor_base + (afluencia / 100000)  # Divide el grosor de la afluencia para que sea mas manejable

        # Color y opacidad
        color = '#e31a1c' if linea == '01' else '#984ea3'

        # Linea al mapa
        folium.GeoJson(
            gpd.GeoSeries([linea_geom]).to_json(),
            style_function=lambda x, c=color, w=weight: {
                'color': c,
                'weight': w,
                'opacity': 0.8
            },
            tooltip=f"Línea {linea} | {mes}<br>Afluencia : {afluencia:,}"
        ).add_to(capa_mes)

    # Se añaden las estaciones
    if mes == 'Febrero':  # Solo las añadimos una vez para evitar duplicados
        for idx, row in estacionesmblinea1y2.iterrows():
            folium.CircleMarker(
                location=[row.geometry.y, row.geometry.x], #ubicacion de las estaciones
                radius=5,
                color='red' if row['LINEA'] == '01' else 'purple', #Color
                fill=True,
                popup=f"{row['NOMBRE']} (Línea {row['LINEA']})" #Para que aparezca el nombre
            ).add_to(m)

    capa_mes.add_to(m)

# 5. Añadir control de capas y leyenda
folium.LayerControl(collapsed=False).add_to(m)

# Mostrar mapa
m

"""# EDA"""

#Df linea 1
df_linea1.head()

#Promedio de afluencia por dia de la semana en la linea 1 del metrobus

# Media de los dias de la semana por linea
df_barras_linea1 = df_linea1.groupby('dia_semana')['afluencia_total'].mean().reset_index()

#Dias de la semana ordenados
nombres_dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']
df_barras_linea1['dia_nombre'] = df_barras_linea1['dia_semana'].map(lambda x: nombres_dias[x])

# Grafico de barras
colores = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']

#Configuracion del grafico
plt.figure(figsize=(10, 6))
plt.bar(df_barras_linea1['dia_nombre'], df_barras_linea1['afluencia_total'], color=colores)
plt.title('Afluencia promedio por dia de la semana en linea 1 del metrobus CDMX 2024')
plt.xlabel('Dia de la semana')
plt.ylabel('Afluencia promedio')
plt.xticks(rotation=45)
plt.grid(False)
plt.show()

#Diagrama de bigotes para afluencia por dia de la semana para la linea 1

# Configuración de tamaño
plt.figure(figsize=(14, 7))

# Gráfico de caja
sns.boxplot(
    x='dia_semana',
    y='afluencia_total',
    data=df_linea1,
    showmeans=True,  # Media con triangulo verde
    flierprops={'marker': 'o', 'markersize': 8},  # Outliers con un circulo
    width=0.6
)

# Etiquetas para el titulo, eje x y eje y
plt.title('Afluencia por dia de la semana en la linea 1 MB CDMX 2024', pad=20)
plt.xlabel('Día de la Semana ', labelpad=10)
plt.ylabel('Afluencia Total', labelpad=10)

# Etiquetas eje x para dias de la semana
plt.xticks(ticks=range(7), labels=nombres_dias, rotation=45, ha='right')

# Ajustes de espacio
plt.tight_layout()
plt.grid(axis='y', alpha=0.3)
plt.show()

#Promedio de afluencia por dia de la semana en la linea 2 del metrobus

# Media de los dias de la semana por linea
df_barras_linea2 = df_linea2.groupby('dia_semana')['afluencia_total'].mean().reset_index()

#Dias de la semana ordenados
nombres_dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']
df_barras_linea2['dia_nombre'] = df_barras_linea2['dia_semana'].map(lambda x: nombres_dias[x])

# Grafico de barras
colores = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']

#Configuracion del grafico
plt.figure(figsize=(10, 6))
plt.bar(df_barras_linea2['dia_nombre'], df_barras_linea2['afluencia_total'], color=colores)
plt.title('Afluencia promedio por dia de la semana en linea 2 del metrobus CDMX 2024')
plt.xlabel('Dia de la semana')
plt.ylabel('Afluencia promedio')
plt.xticks(rotation=45)
plt.grid(False)
plt.show()

#Df linea 2
df_linea2.head()

#Diagrama de bigotes para afluencia por dia de la semana para la linea 2
# Tamaño
plt.figure(figsize=(14, 7))

# Gráfico de caja
sns.boxplot(
    x='dia_semana',
    y='afluencia_total',
    data=df_linea2,
    showmeans=True,  # La media se muestra con un triangulo verde
    flierprops={'marker': 'o', 'markersize': 8},  #Outliers se muestran con un circulo
    width=0.6
)

# Etiquetas para el titulo, eje x y eje y
plt.title('Afluencia por dia de la semana en la linea 2 MB CDM 2024', pad=20)
plt.xlabel('Día de la Semana ', labelpad=10)
plt.ylabel('Afluencia Total', labelpad=10)

# Etiquetas eje x para dias de la semana
plt.xticks(ticks=range(7), labels=nombres_dias, rotation=45, ha='right')

# Ajustes de espacio
plt.tight_layout()
plt.grid(axis='y', alpha=0.3)
plt.show()

"""#ACF Y PACF"""

#LINEA 1

#  ACF
plt.figure(figsize=(12, 6))
plot_acf(df_linea1['afluencia_total'],
         lags=60,          # Analiza los primeros 60 lags (2 meses)
         alpha=0.05,       # Intervalo de confianza del 95%
         title='ACF Afluencia Diaria (Línea 1)')
plt.axvline(x=7, color='red', linestyle='--', alpha=0.5, label='Lag 7 (semanal)')
plt.axvline(x=14, color='blue', linestyle='--', alpha=0.5, label='Lag 14 ')
plt.axvline(x=30, color='green', linestyle='--', alpha=0.5, label='Lag 30(mensual) ')
plt.legend()
plt.show()

# PACF (Función de Autocorrelación Parcial)
plt.figure(figsize=(12, 6))
plot_pacf(df_linea1['afluencia_total'],
          lags=60,
          alpha=0.05,
          title='PACF - Afluencia Diaria (Línea 1)')
plt.axvline(x=7, color='red', linestyle='--', alpha=0.5)
plt.axvline(x=14, color='blue', linestyle='--', alpha=0.5, label='Lag 14 ')
plt.axvline(x=30, color='green', linestyle='--', alpha=0.5)
plt.show()

"""Podemos observar que en la linea 1 encontramos patrones semanales, ya que en el PACF encotramos una relacion significativa respecto el valor actual y el de hace una semana (lag 7) por lo tanto se puede interpretar la existencia de patrones estacionales es decir los valores de la semana pasada seran similares a los de esta semana"""

#LINEA 2

# ACF (Función de Autocorrelación)
plt.figure(figsize=(12, 6))
plot_acf(df_linea2['afluencia_total'],
         lags=60,          # Analisis de los primeros 60 dias
         alpha=0.05,       # Intervalo de confianza del 95%
         title='ACF Afluencia Diaria (Línea 2)')

#Grafico
plt.axvline(x=7, color='red', linestyle='--', alpha=0.5, label='Lag 7 (semanal)')
plt.axvline(x=14, color='blue', linestyle='--', alpha=0.5, label='Lag 14 ')
plt.axvline(x=30, color='green', linestyle='--', alpha=0.5, label='Lag 30(mensual) ')
plt.legend()
plt.show()

# 2. PACF (Función de Autocorrelación Parcial)
#Tamaño
plt.figure(figsize=(12, 6))
plot_pacf(df_linea2['afluencia_total'],
          lags=60,
          alpha=0.05,
          title='PACF - Afluencia Diaria (Línea 2)')

#Grafico
plt.axvline(x=7, color='red', linestyle='--', alpha=0.5)
plt.axvline(x=14, color='blue', linestyle='--', alpha=0.5, label='Lag 14 ')
plt.axvline(x=30, color='green', linestyle='--', alpha=0.5)
plt.show()

"""Podemos observar que en la linea 2 se comporta de manera muy similar a la linea 1, en pocas palabras encontramos patrones semanales, ya que en el PACF se ve una relacion significativa respecto el valor actual y el de hace una semana (lag 7) por lo tanto se puede interpretar la existencia de patrones estacionales es decir los valores de la semana pasada seran similares a los de esta semana

#UNION DE LINEAS PARA CONSTRUCCION DEL MODELO
"""

# Se renombra la afluencia_total para evitar confuciones para la linea 1
df_linea1_renombrado = df_linea1.rename(columns={'afluencia_total': 'afluencia_linea1'})

# Se realiza lo mismo pero para la linea 2
afluencia_linea2 = df_linea2[['afluencia_total']].rename(columns={'afluencia_total': 'afluencia_linea2'})

# Union solo de la columna de afluencia de la linea 2
df_combinado = df_linea1_renombrado.join(afluencia_linea2)

#Reordenar las columnas
columnas_ordenadas = [
    'fecha', 'linea', 'mes', 'anio', 'temporal_fecha',
    'afluencia_linea1', 'afluencia_linea2',
    'temp_aire_celsius', 'precipitacion', 'humedad_especifica',
    'humedad_relativa', 'dia_semana', 'dia_mes',
    'tipo_dia_Entre Semana', 'tipo_dia_Feriado', 'tipo_dia_Fin de Semana'
]

# Se reasigna el df ordenado
df_combinado = df_combinado[columnas_ordenadas]

#Df con la afluencia de la linea 1 y 2 para el año del 2024
df_combinado.head()

#Columnas del df
print(df_combinado.columns)

"""#CREACION DE MEDIAS MOVILES POR LINEA"""

# Copia del df anterior
df_commbinado_con_medias_moviles = df_combinado.copy()

# Medias móviles para Línea 1 (ventana de 7 y 14 movil average)
df_commbinado_con_medias_moviles['ma7_linea1'] = df_commbinado_con_medias_moviles['afluencia_linea1'].shift(1).rolling(7).mean() #(movil average)
df_commbinado_con_medias_moviles['ma14_linea1'] = df_commbinado_con_medias_moviles['afluencia_linea1'].shift(1).rolling(14).mean()

# Medias móviles para Linea 2 (ventana de 7 y 14 movil average)
df_commbinado_con_medias_moviles['ma7_linea2'] = df_commbinado_con_medias_moviles['afluencia_linea2'].shift(1).rolling(7).mean()# (movil average)
df_commbinado_con_medias_moviles['ma14_linea2'] = df_commbinado_con_medias_moviles['afluencia_linea2'].shift(1).rolling(14).mean()

"""#CONSTRUCCION DE LAGS"""

#Creacion de los lags
lags_linea1 = [7,8, 14]  # Lags para la linea 1
lags_linea2 = [7,8, 14]        # Lags significativos para Línea 2 (de PACF)

#Funcion para crear los lags
def crear_lags_por_linea(df, lags_linea1, lags_linea2):
    df = df.copy()

    # Lags linea 1
    for lag in lags_linea1:
        df[f'lag{lag}_linea1'] = df['afluencia_linea1'].shift(lag)

    # Lags linea 2
    for lag in lags_linea2:
        df[f'lag{lag}_linea2'] = df['afluencia_linea2'].shift(lag)

    df = df.dropna()

    return df

#Implementacion de el df ya con los lags correspondientes
df_combinado_con_lags = crear_lags_por_linea(df_commbinado_con_medias_moviles, lags_linea1, lags_linea2)

#Muestra los primeros datos ya con los lags y ma (media movil/ movil average)
df_combinado_con_lags.head()

#CONVERSION DE MESES A NUMERO
# Diccionario de conversión de meses
meses_a_numero = {
    'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4,
    'Mayo': 5, 'Junio': 6, 'Julio': 7, 'Agosto': 8,
    'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12
}

# Aplicar la conversión
df_combinado_con_lags['mes'] = df_combinado_con_lags['mes'].map(meses_a_numero)

#Datos con el mes cambiado a numero
df_combinado_con_lags.head()

# Verifica el total de valores nulos por columna
print(df_combinado_con_lags.isnull().sum())

"""#DIVISION DE LOS DATOS"""

#DIVISION DE LOS DATOS
total_datos = len(df_combinado_con_lags)  # 107 totales
train_size = int(0.8 * total_datos)  # 10 datos (80%)
val_size = int(0.1 * total_datos)    # 12 datos (10%)
test_size = total_datos - train_size - val_size  # 10 datos


# División exacta de train/validation/test
df_train = df_combinado_con_lags.iloc[:train_size]
df_val = df_combinado_con_lags.iloc[train_size:train_size+val_size]
df_test = df_combinado_con_lags.iloc[train_size+val_size:]

#Valores de train/val/test
print(f" Train: {train_size} datos ")
print(f" Val: {val_size} datos ")
print(f" Test: {test_size} datos ")

#Fechas del 2024 que se ocuparan para cada seccion
print("\nFechas en Train:", df_train['fecha'].min(), "a", df_train['fecha'].max())
print("Fechas en Val:", df_val['fecha'].min(), "a", df_val['fecha'].max())
print("Fechas en Test:", df_test['fecha'].min(), "a", df_test['fecha'].max())

# Configuración del gráfico
plt.figure(figsize=(14, 6))
plt.plot(df_train['fecha'], df_train['afluencia_linea1'],
         '#3498db', label=f'Train ({train_size} días)', linewidth=2.5)
plt.plot(df_val['fecha'], df_val['afluencia_linea1'],
         '#e67e22', label=f'Val ({val_size} días)', linewidth=2.5)
plt.plot(df_test['fecha'], df_test['afluencia_linea1'],
         '#2ecc71', label=f'Test ({test_size} días)', linewidth=2.5)


# Datos del grafico
plt.title('División de los datos (80%/10%/10%)', fontsize=14, pad=20)
plt.xlabel('Fecha', fontsize=12)
plt.ylabel('Afluencia', fontsize=12)
plt.legend(loc='upper left', fontsize=10)
plt.grid(alpha=0.2)

# Formato de fechas
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%b'))
plt.gcf().autofmt_xdate()

plt.tight_layout()
plt.show()

print(df_combinado_con_lags.columns)

"""#BUSQUEDA DE HIPERPARAMETROS"""

# 2. Definir caracteristicas comunes entre ambos df
base_features = [
    'mes', 'anio', 'temp_aire_celsius', 'precipitacion',
    'humedad_especifica', 'humedad_relativa', 'dia_semana', 'dia_mes',
    'tipo_dia_Entre Semana', 'tipo_dia_Feriado', 'tipo_dia_Fin de Semana'
]

# 3. Configuracion de parametros
param_grid = {
    'learning_rate':np.arange(0.005, 0.021, 0.005).tolist(), # Valores de aprendizaje
    'max_depth': [1,2,3],              # Profundidad de los arboles, mayor profundidad capta patrones mas complejos pero puede haber sobreajuste
    'n_estimators': [100, 200],  #Arboles de aprendizaje
    'subsample': [0.7, 0.8],        #Fraccion de muestra usada para entrenar cada arbol
    'colsample_bytree': [0.7, 0.8],  #Características usadas para cada árbol
    'gamma': [0, 0.1, 0.2],              # Pérdida minima para hacer una división en un nodo
    'reg_alpha': [1,2,3,4,5],            # Regularización L1/penaliza pesos grandes
    'reg_lambda': [1,2,3,4,5],           # Regularización L2/reduce magnitud de pesos
    'min_child_weight': [5,7]        # Control de sobreajuste/ restricción que evita que el árbol se divida en nodos con muy pocos datos o con poca "importancia" estadística
}

"""#BUSQUEDA DE HIPERPARAMETROS LINEA 1"""

#BUSQUEDA DE HIPERPARAMETROS LINEA 1
# Función de evaluacion para los posibles parametros planteados
def evaluacion_de_hiperparametros_linea1(features, target, X_train, y_train, X_val, y_val):
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        random_state=42,
        early_stopping_rounds=3,
        n_jobs=-1
    )

    # Validación cruzada temporal (3 pliegues)
    tscv = TimeSeriesSplit(n_splits=3)



    search = RandomizedSearchCV(
        model,
        param_grid,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_iter=30,
        random_state=42
    )
    eval_size = int(0.2 * len(X_train))
    eval_set = [(X_train[-eval_size:], y_train[-eval_size:])]

    search.fit(
        X_train, y_train,
        eval_set=eval_set,
        verbose=False
    )


  # Evaluación en el conjunto de validacion
    val_pred = search.predict(X_val)
    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
    train_rmse = np.sqrt(mean_squared_error(y_train, search.predict(X_train)))
    # Visualizacion del sobreajuste
    overfit = train_rmse - val_rmse

    return {
        'best_params': search.best_params_,
        'train_rmse': train_rmse,
        'val_rmse': val_rmse,
        'overfit': overfit,
        'model': search.best_estimator_
    }

# Evaluación con menos combinaciones
mejores_resultados_linea1 = []
target = 'afluencia_linea1'

# Mejores 2 combinaciones en base al analisis previo
combinaciones_optimizadas_linea1 = [

    ['lag7_linea1', 'lag14_linea1'],
    ["lag7_linea1", "ma7_linea1"],
    ["lag7_linea1", "ma14_linea1"],
    ["lag14_linea1", "ma14_linea1"],
    ['lag7_linea1', 'lag14_linea1', 'ma7_linea1'],
    ['lag7_linea1', 'lag14_linea1', 'ma14_linea1'],
    ['ma7_linea1', 'ma14_linea1'],
    ['lag7_linea1', 'ma7_linea1', 'ma14_linea1']
]

print("EVALUACIÓN PARAMETROS LINEA 1")
for lags in combinaciones_optimizadas_linea1:
    features = base_features + lags

    # Preparar datos
    X_train = df_train[features]
    y_train = df_train[target]
    X_val = df_val[features]
    y_val = df_val[target]

    # Evalua modelo
    resultado = evaluacion_de_hiperparametros_linea1(features, target, X_train, y_train, X_val, y_val)

    print(f"\nCombinación: {lags}")
    print(f"RMSE Entrenamiento: {resultado['train_rmse']:.2f}")
    print(f"RMSE Validación: {resultado['val_rmse']:.2f}")
    print(f"Diferencia (sobreajuste): {resultado['overfit']:.2f}")

    mejores_resultados_linea1.append(resultado)

# Selección del mejor modelo
mejor_modelo_linea1 = min(mejores_resultados_linea1, key=lambda x: x['val_rmse'])

print("\n MEJOR MODELO ")
print(f"Combinación de lags: {combinaciones_optimizadas_linea1[mejores_resultados_linea1.index(mejor_modelo_linea1)]}")
print(f"RMSE Validación: {mejor_modelo_linea1['val_rmse']:.2f}")
print(f"Parametros: {mejor_modelo_linea1['best_params']}")
print(f"Diferencia entrenamiento/validación: {mejor_modelo_linea1['overfit']:.2f}")

"""#BUSQUEDA DE HIPERPARAMETROS LINEA 2"""

#Función de evaluacion linea 2
def evaluacion_de_hiperparametros_linea2(features, target, X_train, y_train, X_val, y_val):
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        random_state=42,
        early_stopping_rounds=3,
        n_jobs=-1
    )

    tscv = TimeSeriesSplit(n_splits=3)

    search = RandomizedSearchCV(
        model,
        param_grid,
        cv=tscv,
        scoring='neg_mean_squared_error',
        n_iter=30,
        random_state=42
    )

    eval_size = int(0.2 * len(X_train))
    eval_set = [(X_train[-eval_size:], y_train[-eval_size:])]

    search.fit(
        X_train, y_train,
        eval_set=eval_set,
        verbose=False
    )

    val_pred = search.predict(X_val)
    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
    train_rmse = np.sqrt(mean_squared_error(y_train, search.predict(X_train)))
    overfit = train_rmse - val_rmse

    return {
        'best_params': search.best_params_,
        'train_rmse': train_rmse,
        'val_rmse': val_rmse,
        'overfit': overfit,
        'model': search.best_estimator_
    }

# Evaluación para Línea 2
mejores_resultados_linea2 = []
target = 'afluencia_linea2'

# Mismas combinaciones que para Línea 1
combinaciones_optimizadas_linea2 = [
    ['lag7_linea2', 'lag14_linea2'],
    ["lag7_linea2", "ma7_linea2"],
    ["lag7_linea2", "ma14_linea2"],
    ["lag14_linea2", "ma14_linea2"],
    ['lag7_linea2', 'lag14_linea2', 'ma7_linea2'],
    ['lag7_linea2', 'lag14_linea2', 'ma14_linea2'],
    ['ma7_linea2', 'ma14_linea2'],
    ['lag7_linea2', 'ma7_linea2', 'ma14_linea2']
]

print("EVALUACIÓN PARAMETROS LINEA 2")
for lags in combinaciones_optimizadas_linea2:
    features = base_features + lags

    X_train = df_train[features]
    y_train = df_train[target]
    X_val = df_val[features]
    y_val = df_val[target]

    resultado = evaluacion_de_hiperparametros_linea2(features, target, X_train, y_train, X_val, y_val)

    print(f"\nCombinación: {lags}")
    print(f"RMSE Entrenamiento: {resultado['train_rmse']:.2f}")
    print(f"RMSE Validación: {resultado['val_rmse']:.2f}")
    print(f"Diferencia (sobreajuste): {resultado['overfit']:.2f}")

    mejores_resultados_linea2.append(resultado)

# Selección del mejor modelo para Línea 2
mejor_modelo_linea2 = min(mejores_resultados_linea2, key=lambda x: x['val_rmse'])

print("\n MEJOR MODELO LINEA 2")
print(f"Combinación de lags: {combinaciones_optimizadas_linea2[mejores_resultados_linea2.index(mejor_modelo_linea2)]}")
print(f"RMSE Validación: {mejor_modelo_linea2['val_rmse']:.2f}")
print(f"Parametros: {mejor_modelo_linea2['best_params']}")
print(f"Diferencia entrenamiento/validación: {mejor_modelo_linea2['overfit']:.2f}")

"""#IMPLEMENTACION DEL MODELO LINEA 1 (2024)"""

#HIPERPARAMETROS RECOMENDADOS PARA LA LINEA 1
print("Hiperparametros recomendados para la linea 1:", mejor_modelo_linea1['best_params'])
print("Lags recomendados para la linea 1:", combinaciones_optimizadas_linea1[mejores_resultados_linea1.index(mejor_modelo_linea1)])

"""En la busqueda de hiperparametros para la linea 1 y al probar los lags y MA se encontro que la que tenia el RMSE mas bajo en validacion era ['lag4_linea1', 'lag 14_linea1'] con un valor de 48,246.13, sin embargo para el modelo final se implemento ['lag7_linea1', 'lag14_linea1', 'ma7_linea1'] con un RMSE en validacion de 50,340.94 debido a que la diferencia entre ambas es pequeña y podria existir una mejor captura de patrones semanales"""

# Linea 1 caracteristicas finales para implementacion
#Features finales para la linea 1
features_finales_linea1 = base_features + ['lag7_linea1', 'lag14_linea1', 'ma7_linea1']
#Union del train y val
X_train_val = pd.concat([df_train, df_val])[features_finales_linea1]
y_train_val = pd.concat([df_train, df_val])['afluencia_linea1']
#Evalucacion de los datos en test
X_test = df_test[features_finales_linea1]
y_test = df_test['afluencia_linea1']

#Configuracion de XGBOOST
modelo_final_linea1 = xgb.XGBRegressor(
    objective='reg:squarederror',
    **mejor_modelo_linea1['best_params'],  #Mejores parametros encontrados
    n_jobs=-1,
    random_state=42
)

#  Entrenamiento
modelo_final_linea1.fit(X_train_val, y_train_val)

"""#METRICAS LINEA 1 2024"""

# Predicciones para la linea 1
test_pred = modelo_final_linea1.predict(X_test)

# Métricas
#RMSE
rmse_test = np.sqrt(mean_squared_error(y_test, test_pred))
#MAE
mae_test = mean_absolute_error(y_test, test_pred)
# MAPE
mape_test = np.mean(np.abs((y_test - test_pred) / y_test)) * 100

#Impresion de las metricas
print(f"Metricas para la linea 1 (2024):")
print(f"RMSE en test: {rmse_test:.2f}")
print(f"MAE en test: {mae_test:.2f}")
print(f"MAPE en test: {mape_test:.2f}%")

# Gráfico de predicciones vs real
plt.figure(figsize=(12, 6))
plt.plot(df_test['fecha'], y_test, label='Real', color='red')
plt.plot(df_test['fecha'], test_pred, label='Predicho', linestyle='--', color='green')
plt.title('Predicciones vs Real para Linea 1 del mb CDMX(2024)')
plt.legend()
plt.show()

"""#IMPLEMENTACION DEL MODELO PARA LA LINEA 2"""

#HIPERPARAMETROS RECOMENDADOS PARA LA LINEA 2
print("Hiperparametros recomendados para la linea 2:", mejor_modelo_linea2['best_params'])
print("Lags y MA recomendafos para la linea 2:", combinaciones_optimizadas_linea2[mejores_resultados_linea2.index(mejor_modelo_linea2)])

"""En la busqueda de hiperparametros para la linea 2 y al probar los lags y MA se encontro que la que tenia el RMSE mas bajo en validacion era ['lag14_linea2', 'ma14_linea2'] con un valor de 32665.97 ,  sin embargo he decidido implementar para el modelo final  ['lag7_linea2', 'lag14_linea2', 'ma14_linea2'] con un
RMSE en validacion de 33645.65 debido a que la diferencia entre ambas es alrededor de un 3% y podria existir una mejor captura de patrones semanales
"""

# Features finales
features_finales_linea2 = base_features + ['lag7_linea2','lag14_linea2','ma14_linea2' ]  # << Reemplaza con la mejor combinación encontrada para Línea 2

# 2. Unir train + validation para Línea 2
X_train_val_linea2 = pd.concat([df_train, df_val])[features_finales_linea2]
y_train_val_linea2 = pd.concat([df_train, df_val])['afluencia_linea2']  # << Target de Línea 2

# 3. Preparar datos de test para Línea 2
X_test_linea2 = df_test[features_finales_linea2]
y_test_linea2 = df_test['afluencia_linea2']

# 4. Configurar modelo para klínea 2
modelo_final_linea2 = xgb.XGBRegressor(
    objective='reg:squarederror',
    **mejor_modelo_linea2['best_params'],  # << Hiperparámetros óptimos de Línea 2
    n_jobs=-1,
    random_state=42
)

# Entrenar el modelo para línea 2
modelo_final_linea2.fit(X_train_val_linea2, y_train_val_linea2)

"""#METRICAS PARA LA LINEA 2 (2024)"""

#Evaluar en test para línea 2 para 2024
y_pred_linea2 = modelo_final_linea2.predict(X_test_linea2)
rmse_test_linea2 = np.sqrt(mean_squared_error(y_test_linea2, y_pred_linea2))
mae_test_linea2 = mean_absolute_error(y_test_linea2, y_pred_linea2)
mape_test_linea2 = np.mean(np.abs((y_test_linea2 - y_pred_linea2) / y_test_linea2)) * 100

print(f"\Metricas para Linea 2 (2024):")
print(f"- RMSE en test: {rmse_test_linea2:.2f}")
print(f"- MAE en test: {mae_test_linea2:.2f}")
print(f"- MAPE en test: {mape_test_linea2:.2f}%")

#Grafico para Linea 2
plt.figure(figsize=(12, 6))
plt.plot(df_test['fecha'], y_test_linea2, label='Real', color='purple')
plt.plot(df_test['fecha'], y_pred_linea2, label='Predicho', linestyle='--', color='green')
plt.title('Predicciones vs Real Linea 2 del mb de la CDMX (2024)')
plt.legend()
plt.show()

print(modelo_final_linea1.feature_names_in_)

print(modelo_final_linea2.feature_names_in_)

"""#PREDICCIONES PARA 2025

"""

#Base de datos para las predicciones de 2025

# Fechas para 2025 (febrero a mayo 2025)
fechas_2025 = pd.date_range(start="2025-02-01", end="2025-05-31", freq='D')

# Df base para 2025
df_2025 = pd.DataFrame({'fecha': fechas_2025})

#Implementacion de la funcion
df_2025 = dias_xgboost(df_2025, year=2025).reset_index(drop=True)

# Extraer mes y año
df_2025['mes'] = df_2025['fecha'].dt.month #ya en formato entero
df_2025['anio'] = df_2025['fecha'].dt.year #en formato entero

df_2025.head()

#Informacion del df hasta el momento
df_2025.info()

#IMPLEMETACION DE DATOS CLIMATOLOGICOS PARA 2025

"""Los datos del clima fueron obtenidos de
https://power.larc.nasa.gov/data-access-viewer/
"""

# Se agrega las variable de clima (incluye temperatura del aire, precipitacion,humedad especifica y humedad relativa)
#datosclima_2025=pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/climacdmx/datosclima2025/clima_2025final.csv")

datosclima_2025 = pd.read_csv("clima_2025final.csv")

#UNION DE LOS DF
#Resetea el indice de cada set
df_2025 = df_2025.reset_index(drop=True)
datosclima_2025 = datosclima_2025.reset_index(drop=True)

# Une solo las columnas de clima por el índice
df_2025 = df_2025.join(datosclima_2025[['temp_aire_celsius', 'precipitacion', 'humedad_especifica', 'humedad_relativa']])

import pandas as pd

# 1. Columnas a convertir
columnas_problematicas = ['temp_aire_celsius', 'precipitacion', 'humedad_especifica', 'humedad_relativa']

# 2. Función para limpieza robusta (con reemplazo de NaN por 0)
def clean_to_float(serie):
    return (
        serie
        .astype(str)
        .str.replace(',', '.', regex=False)  # Reemplazar comas por puntos
        .str.replace(r'[^\d.-]', '', regex=True)  # Eliminar símbolos no numéricos
        .replace('', '0')  # Convertir vacíos a "0" (en lugar de NaN)
        .astype(float)  # Conversión final
    )

# 3. Aplicar a cada columna
for col in columnas_problematicas:
    df_2025[col] = clean_to_float(df_2025[col])

df_2025.info()

"""#BASE AFLUENCIA 2025(datos de enero 2025 18-31)
Para la generacion de los lags
"""

#Datos de la afluencia de la linea 1, desde el 18 de enero 2025 al 31 de enero 2025 para la generacion de los lags
#datos_afluencia_linea1_2025 = pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/afluencia2025/afluencia2025linea1/afluencia_linea1_2025.csv")
datos_afluencia_linea1_2025 = pd.read_csv("afluencia_linea1_2025.csv")
print(datos_afluencia_linea1_2025.head())

#Se aplica la funcion procesar_afluencia para unir los datos
#Linea 1
datos_afluencia_linea1_2025_procesado = procesar_afluencia(datos_afluencia_linea1_2025)
#Se renombra la columna de afluencia total para mayor claridad
datos_afluencia_linea1_2025_procesado.rename(columns={'afluencia_total': 'afluenciat_linea1_2025'}, inplace=True)
print(datos_afluencia_linea1_2025_procesado.head())
print(datos_afluencia_linea1_2025_procesado.info())

"""#Creacion de lags para la linea 1"""

# Datos historicos
df_historico_linea1_2025 = datos_afluencia_linea1_2025_procesado.copy()
df_historico_linea1_2025['fecha'] = pd.to_datetime(df_historico_linea1_2025['fecha'])

# Df de prediccion (febrero-mayo 2025)
rango_pred_linea1 = pd.date_range(start="2025-02-01", end="2025-05-31", freq='D')
df_pred_linea1 = pd.DataFrame({
    'fecha': rango_pred_linea1,
    'afluencia': np.nan  # Columna para predicciones futuras
})

#Combinacion de los datos
df_full_linea1_2025 = pd.concat([df_historico_linea1_2025, df_pred_linea1]).sort_values('fecha').reset_index(drop=True)

#Inicializacion de lags
df_full_linea1_2025['lag7_linea1'] = df_full_linea1_2025['afluenciat_linea1_2025'].shift(7)
df_full_linea1_2025['lag14_linea1'] = df_full_linea1_2025['afluenciat_linea1_2025'].shift(14)
df_full_linea1_2025['ma7_linea1'] = np.nan  # Inicializar como NaN

# Simulacion de los lags y ma
for i in range(len(df_full_linea1_2025)):
    if pd.isna(df_full_linea1_2025.loc[i, 'afluenciat_linea1_2025']):

        if i < 1:  # Para el primer día de predicción
            valor_base = df_full_linea1_2025.loc[i-1, 'afluenciat_linea1_2025'] if i > 0 else df_historico_linea1_2025['afluenciat_linea1_2025'].iloc[-1]
        else:
            valor_base = df_full_linea1_2025.loc[i-1, 'afluenciat_linea1_2025']


        df_full_linea1_2025.loc[i, 'afluenciat_linea1_2025'] = valor_base * 0.98  # -2% diario

        # Actualiza los lags
        for dias in [7, 14]:
            if i + dias < len(df_full_linea1_2025):
                df_full_linea1_2025.loc[i+dias, f'lag{dias}_linea1'] = df_full_linea1_2025.loc[i, 'afluenciat_linea1_2025']

        # Actualiza ma
        if i >= 6:
            df_full_linea1_2025.loc[i, 'ma7_linea1'] = df_full_linea1_2025.loc[i-6:i, 'afluenciat_linea1_2025'].mean()
        # Actualizar medias móviles futuras
        for dias_futuros in range(1, min(7, len(df_full_linea1_2025)-i)):
            ventana_inicio = i - 6 + dias_futuros
            if ventana_inicio >= 0:
                df_full_linea1_2025.loc[i+dias_futuros, 'ma7_linea1'] = df_full_linea1_2025.loc[ventana_inicio:i+dias_futuros, 'afluenciat_linea1_2025'].mean()

# Resultados (febrero-mayo 2025)
lags_ma_2025 = df_full_linea1_2025[(df_full_linea1_2025['fecha'] >= '2025-02-01') &
                    (df_full_linea1_2025['fecha'] <= '2025-05-31')].copy()

# Verificación final
print("Valores nulos en lags:", lags_ma_2025[['lag7_linea1', 'lag14_linea1']].isna().sum())
print("\nPrimeras 10 filas:")

#Reseteo del indice para que sea igual al de df_2025
lags_ma_2025.reset_index(drop=True, inplace=True)
print(lags_ma_2025.tail())

#DF solo con los lags para la linea 1 del año 2025
df_lags_linea1_2025=lags_ma_2025[['lag7_linea1','lag14_linea1','ma7_linea1']]
print(df_lags_linea1_2025.tail())

#Se unen los df
df_completo_linea1_2025 = pd.concat([df_2025.drop(columns=['fecha']), df_lags_linea1_2025], axis=1)
#Orden para que sea el mismo que xgboost
df_completo_linea1_2025 = df_completo_linea1_2025.loc[:, ['mes', 'anio', 'temp_aire_celsius', 'precipitacion', 'humedad_especifica',
               'humedad_relativa', 'dia_semana', 'dia_mes', 'tipo_dia_Entre Semana',
               'tipo_dia_Feriado', 'tipo_dia_Fin de Semana', 'lag7_linea1', 'lag14_linea1',
               'ma7_linea1']]

print(df_completo_linea1_2025.tail())

"""#Prediccion de afluencia para la linea 1"""

print(modelo_final_linea1.feature_names_in_)
print(df_completo_linea1_2025.columns)

# Generar predicciones
predicciones_linea1_2025 = modelo_final_linea1.predict(df_completo_linea1_2025)

# Añadir predicciones al DataFrame (opcional)
df_completo_linea1_2025['prediccion'] = predicciones_linea1_2025

print(df_completo_linea1_2025[['prediccion']].tail(50))  # Ultimas filas

#Predicciones para la afluencia linea 2 2025 (febrero a mayo 2025)
df_predicciones_final_linea1_2025= pd.DataFrame({
    'fecha': fechas_2025,
    'prediccion_afluencia_linea1_2025': predicciones_linea1_2025
})


# 4. Mostrar las primeras filas
print("Primeras 5 predicciones para la afluencia :")
print(df_predicciones_final_linea1_2025.tail())

# Diccionario de meses en español
meses_es = {
    1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril',
    5: 'Mayo', 6: 'Junio', 7: 'Julio', 8: 'Agosto',
    9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'
}

# Columanas en español
df_predicciones_final_linea1_2025['mes'] = (
    df_predicciones_final_linea1_2025['fecha'].dt.month.map(meses_es))

print(df_predicciones_final_linea1_2025.tail())

"""#Datos de afluencia de la linea  2 del 18 al 31 de enero 2025"""

#Datos de la afluencia de la linea 2, desde el 18 de enero 2025 al 31 de enero 2025 para la generacion de los lags
#datos_afluencia_linea2_2025 = pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/afluencia2025/afluencia2025linea2/afluencia_linea2_2025.csv")
datos_afluencia_linea2_2025 = pd.read_csv("afluencia_linea2_2025.csv")
print(datos_afluencia_linea2_2025.head())

#Linea 2
datos_afluencia_linea2_2025_procesado = procesar_afluencia(datos_afluencia_linea2_2025)
#Se renombra la columna de afluencia total para mayor claridad
datos_afluencia_linea2_2025_procesado.rename(columns={'afluencia_total': 'afluenciat_linea2_2025'}, inplace=True)
print(datos_afluencia_linea2_2025_procesado.head())

print(datos_afluencia_linea2_2025_procesado.info())

"""#Creacion de lags para la linea 2"""

#Datos historicos
df_historico_linea2_2025 = datos_afluencia_linea2_2025_procesado.copy()
df_historico_linea2_2025['fecha'] = pd.to_datetime(df_historico_linea2_2025['fecha'])

# Df prediccion (febrero-mayo 2025)
rango_pred_linea2 = pd.date_range(start="2025-02-01", end="2025-05-31", freq='D')
df_pred_linea2 = pd.DataFrame({
    'fecha': rango_pred_linea2,
    'afluenciat_linea2_2025': np.nan  # Usar el nombre exacto de la columna
})

# Combinar datos
df_full_linea2_2025 = pd.concat([df_historico_linea2_2025, df_pred_linea2]).sort_values('fecha').reset_index(drop=True)

#Inicializar los lags
df_full_linea2_2025['lag7_linea2'] = df_full_linea2_2025['afluenciat_linea2_2025'].shift(7)
df_full_linea2_2025['lag14_linea2'] = df_full_linea2_2025['afluenciat_linea2_2025'].shift(14)
df_full_linea2_2025['ma14_linea2'] = np.nan  # Inicializar MA14

# Simulación de los lags y MA14
for i in range(len(df_full_linea2_2025)):
    if pd.isna(df_full_linea2_2025.loc[i, 'afluenciat_linea2_2025']):

        if i < 1:  # Para el primer día de predicción
            valor_base_linea2 = df_full_linea2_2025.loc[i-1, 'afluenciat_linea2_2025'] if i > 0 else df_historico_linea2_2025['afluenciat_linea2_2025'].iloc[-1]
        else:
            valor_base_linea2 = df_full_linea2_2025.loc[i-1, 'afluenciat_linea2_2025']

        # Valores sintéticos que disminuyen en un 2% diario
        df_full_linea2_2025.loc[i, 'afluenciat_linea2_2025'] = valor_base_linea2 * 0.98

        # Lags
        for dias in [7, 14]:
            if i + dias < len(df_full_linea2_2025):
                df_full_linea2_2025.loc[i+dias, f'lag{dias}_linea2'] = df_full_linea2_2025.loc[i, 'afluenciat_linea2_2025']

    # Ma14
    if i >= 13:
        df_full_linea2_2025.loc[i, 'ma14_linea2'] = df_full_linea2_2025.loc[i-13:i, 'afluenciat_linea2_2025'].mean()

# Resultados
lags_ma_2025_linea2 = df_full_linea2_2025[(df_full_linea2_2025['fecha'] >= '2025-02-01') &
                                 (df_full_linea2_2025['fecha'] <= '2025-05-31')].copy()

# Verificación final
print("Valores nulos en lags_ma_2025_linea2 y MA14:")
print(lags_ma_2025_linea2[['lag7_linea2', 'lag14_linea2', 'ma14_linea2']].isna().sum())
print("\nPrimeras 10 filas:")
print(lags_ma_2025_linea2[['fecha', 'afluenciat_linea2_2025', 'lag7_linea2', 'lag14_linea2', 'ma14_linea2']].head(10))

#Reseteo del indice para que sea igual al de df_2025
lags_ma_2025_linea2.reset_index(drop=True, inplace=True)
print(lags_ma_2025_linea2.tail())

#DF solo con los lags para la linea 1 del año 2025
df_lags_linea2_2025=lags_ma_2025_linea2[['lag7_linea2','lag14_linea2','ma14_linea2']]
print(df_lags_linea2_2025.tail())

#Se unen los df
df_completo_linea2_2025 = pd.concat([df_2025.drop(columns=['fecha']), df_lags_linea2_2025], axis=1)
#Orden para que sea el mismo que xgboost
df_completo_linea2_2025 = df_completo_linea2_2025.loc[:, ['mes', 'anio', 'temp_aire_celsius', 'precipitacion', 'humedad_especifica',
               'humedad_relativa', 'dia_semana', 'dia_mes', 'tipo_dia_Entre Semana',
               'tipo_dia_Feriado', 'tipo_dia_Fin de Semana', 'lag7_linea2', 'lag14_linea2',
               'ma14_linea2']]

print(df_completo_linea2_2025.tail())

"""#Prediccion para la linea 2"""

# Genera predicciones
predicciones_linea2_2025 = modelo_final_linea2.predict(df_completo_linea2_2025)

#Predicciones en el df completo
df_completo_linea2_2025['prediccion'] = predicciones_linea2_2025

print(df_completo_linea2_2025[['prediccion']].tail(50))  # Primeras filas

#Predicciones para la afluencia linea 2 2025 (febrero a mayo 2025)
df_predicciones_final_linea2_2025= pd.DataFrame({
    'fecha': fechas_2025,
    'prediccion_afluencia_linea2_2025': predicciones_linea2_2025  # Asegúrate de que coincidan en longitud
})


#Muestra las primeras filas
print("Primeras 5 predicciones para la afluencia :")
print(df_predicciones_final_linea2_2025.head())

# Extraer el número del mes de la columna 'fecha' y mapear al nombre en español
df_predicciones_final_linea2_2025['mes'] = (
    df_predicciones_final_linea2_2025['fecha'].dt.month.map(meses_es))

print(df_predicciones_final_linea2_2025.head())
print(df_predicciones_final_linea2_2025.tail())

# Meses
print("Meses únicos en df_predicciones_final_linea1_2025:", df_predicciones_final_linea1_2025['mes'].unique())
print("Meses que estás buscando:", meses)  # ['Febrero', 'Marzo', ...]

"""#MAPA AFLUENCIA PREDICHA PARA 2025"""

# Mapa de la CDMX centrado
m = folium.Map(location=[19.4326, -99.1332], zoom_start=12)

# Estaciones por línea
estaciones_por_linea = {
    '01': ["Indios Verdes", "Dep. 18 de Marzo", "Eúzkaro", "Potrero", "La Raza", "Circuito", "San Simón",
           "Manuel González", "Buenavista", "El Chopo", "Revolución", "Plaza de la República", "Reforma", "Hamburgo",
           "Insurgentes", "Durango", "Álvaro Obregón", "Sonora", "Campeche", "Chilpancingo", "Nuevo León", "La Piedad",
           "Polifórum", "Nápoles", "Colonia del Valle", "Ciudad de los Deportes", "Parque Hundido", "Félix Cuevas",
           "Río Churubusco", "Teatro de los Insurgentes", "José María Velasco", "Francia", "Olivo", "Altavista",
           "La Bombilla", "Doctor Gálvez", "Ciudad Universitaria", "C.C.U.", "Perisur", "Villa Olímpica",
           "Corregidora", "Ayuntamiento", "Fuentes Brotantes", "Santa Úrsula", "La Joya", "El Caminero"],
    '02': ["Tacubaya", "Parque Lira", "Antonio Maceo", "De la Salle", "Patriotismo", "Escandón", "Nuevo León",
           "Viaducto", "Amores", "Etiopía", "Doctor Vértiz", "Centro SCOP", "Álamos", "Xola", "Las Américas",
           "Andrés Molina Enríquez", "La Viga", "Coyuya", "Metro Coyuya", "Canela", "Tlacotal", "Goma", "Iztacalco",
           "UPIICSA", "El Rodeo", "Río Tecolutla", "Río Mayo", "Rojo Gómez", "Río Frío", "Leyes de Reforma",
           "Del Moral", "CCH Oriente", "Const. de Apatzingán", "Gral. Antonio de León", "Canal de San Juan",
           "Nicolás Bravo", "Tepalcates"]
}

# Función para crear líneas a partir de las estaciones
def crear_linea_desde_estaciones(linea):
    coords = []
    for nombre_estacion in estaciones_por_linea[linea]:
        estacion = estacionesmblinea1y2[estacionesmblinea1y2['NOMBRE'] == nombre_estacion]
        if not estacion.empty:
            coords.append((estacion.iloc[0].geometry.x, estacion.iloc[0].geometry.y))
    return LineString(coords) if coords else None

# Mapeo de número de mes a nombre en español
meses_es = {2: 'Febrero', 3: 'Marzo', 4: 'Abril', 5: 'Mayo'}
orden_meses = ['Febrero', 'Marzo', 'Abril', 'Mayo']

# Agrega columna 'mes' a los df
df_predicciones_final_linea1_2025['mes'] = df_predicciones_final_linea1_2025['fecha'].dt.month.map(meses_es)
df_predicciones_final_linea2_2025['mes'] = df_predicciones_final_linea2_2025['fecha'].dt.month.map(meses_es)

# Asegurar tipo de datos correcto
df_predicciones_final_linea1_2025['prediccion_afluencia_linea1_2025'] = df_predicciones_final_linea1_2025['prediccion_afluencia_linea1_2025'].astype(float)
df_predicciones_final_linea2_2025['prediccion_afluencia_linea2_2025'] = df_predicciones_final_linea2_2025['prediccion_afluencia_linea2_2025'].astype(float)

# Obtener los meses disponibles ordenados
meses_disponibles = sorted(
    df_predicciones_final_linea1_2025['mes'].unique(),
    key=lambda x: orden_meses.index(x)
)

# Crear capas por mes
for i, mes in enumerate(meses_disponibles):
    capa_mes = folium.FeatureGroup(name=f'Predicción 2025 - {mes}', show=(i == 0))

    for linea in ['01', '02']:
        linea_geom = crear_linea_desde_estaciones(linea)
        if not linea_geom:
            continue

        # Calcular afluencia total por línea y mes
        if linea == '01':
            afluencia = df_predicciones_final_linea1_2025[df_predicciones_final_linea1_2025['mes'] == mes]['prediccion_afluencia_linea1_2025'].sum()
        else:
            afluencia = df_predicciones_final_linea2_2025[df_predicciones_final_linea2_2025['mes'] == mes]['prediccion_afluencia_linea2_2025'].sum()

        # Estilo de la línea
        grosor_base = 2 if linea == '01' else 1
        weight = grosor_base + (afluencia / 100000)
        color = '#e31a1c' if linea == '01' else '#984ea3'

        # Agregar línea al mapa
        folium.GeoJson(
            gpd.GeoSeries([linea_geom]).to_json(),
            style_function=lambda x, c=color, w=weight: {
                'color': c,
                'weight': w,
                'opacity': 0.8
            },
            tooltip=f"Línea {linea} | {mes} 2025<br>Predicción total: {afluencia:,.0f}"
        ).add_to(capa_mes)

    # Agregar estaciones solo en la primera capa
    if mes == meses_disponibles[0]:
        for idx, row in estacionesmblinea1y2.iterrows():
            folium.CircleMarker(
                location=[row.geometry.y, row.geometry.x],
                radius=5,
                color='red' if row['LINEA'] == '01' else 'purple',
                fill=True,
                popup=f"{row['NOMBRE']} (Línea {row['LINEA']})"
            ).add_to(m)

    capa_mes.add_to(m)

# Control de capas
folium.LayerControl(collapsed=False).add_to(m)

# Mostrar mapa
m

"""#RESULTADOS PARA PREDICCION 2025"""

#Coumnas para la linea 1 y 2
print(df_predicciones_final_linea1_2025.columns)

# Gráfico de líneas (1 y 2)
plt.figure(figsize=(10, 6))
plt.plot(df_predicciones_final_linea1_2025['fecha'], df_predicciones_final_linea1_2025['prediccion_afluencia_linea1_2025'], label='Línea 1',color="#FF6666")
plt.plot(df_predicciones_final_linea2_2025['fecha'], df_predicciones_final_linea2_2025['prediccion_afluencia_linea2_2025'], label='Línea 2',color="purple")

# Configuracion el gráfico
plt.title('Prediccciones linea 1 y 2 (febrero-mayo 2025)')#titulo
plt.ylabel('Personas por linea')#etiqueta del eje y
plt.xlabel('Afluencia predicha de febrero a mayo 2025')#etiqueta del eje x
plt.xticks([])  #Se elimina todas las etiquetas del eje X
plt.legend()  # Muestra la leyenda para distinguir entre líneas
plt.tight_layout()  # Ajusta el espacio entre elementos del gráfico
plt.show()#Muestra el grafico

# Orden en base al mes (febrero a mayo 2025)
df_linea1_mes = df_predicciones_final_linea1_2025.groupby('mes')['prediccion_afluencia_linea1_2025'].sum().reset_index()
df_linea2_mes = df_predicciones_final_linea2_2025.groupby('mes')['prediccion_afluencia_linea2_2025'].sum().reset_index()

orden_meses = ['Febrero', 'Marzo', 'Abril', 'Mayo']
df_linea1_mes['mes'] = pd.Categorical(df_linea1_mes['mes'], categories=orden_meses, ordered=True)
df_linea2_mes['mes'] = pd.Categorical(df_linea2_mes['mes'], categories=orden_meses, ordered=True)

# Ordenar por mes
df_linea1_mes = df_linea1_mes.sort_values('mes')
df_linea2_mes = df_linea2_mes.sort_values('mes')

# Tamaño del gráfico
plt.figure(figsize=(10, 6))

# Orden de los meses para eje x
x = range(len(orden_meses))  # Posiciones 0,1,2,3 correspondientes a los meses

# Línea 1
plt.plot(x, df_linea1_mes['prediccion_afluencia_linea1_2025'],
         label='Línea 1',#Etiqueta
         color="#FF6666",  # Color rojo claro
         marker='o',#Circulo  en el mes correspondiente
         linewidth=2)#Grosor de la linea

# Línea 2
plt.plot(x, df_linea2_mes['prediccion_afluencia_linea2_2025'],
         label='Línea 2',#Etiqueta
         color="purple",  # Color morado
         marker='o',#Circulo  en el mes correspondiente
         linewidth=2)#Grosor de la linea

# Etiquetas para mostrar  la afluencia por mes
for i, val in enumerate(df_linea1_mes['prediccion_afluencia_linea1_2025']):
    plt.text(i, val + 5000, f"{val:,.0f}", ha='center', va='bottom', fontsize=9)

for i, val in enumerate(df_linea2_mes['prediccion_afluencia_linea2_2025']):
    plt.text(i, val + 5000, f"{val:,.0f}", ha='center', va='bottom', fontsize=9)

# Configuración del gráfico
plt.title('Predicción de afluencia por mes  en las lineas 1 y 2 (Febrero-Mayo 2025)')
plt.xlabel('Mes')
plt.ylabel('Afluencia Total Predicha')
plt.xticks(x, orden_meses)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()

# Mostrar
plt.show()

# Estadisticos descriptivos para línea 1 y línea 2
descriptivos_linea1_2025 = df_predicciones_final_linea1_2025['prediccion_afluencia_linea1_2025'].describe()
descriptivos_linea2_2025= df_predicciones_final_linea2_2025['prediccion_afluencia_linea2_2025'].describe()


df_descriptivos_pred_2025 = pd.DataFrame({
    'Línea 1': descriptivos_linea1_2025,
    'Línea 2': descriptivos_linea2_2025
}).transpose()

df_descriptivos_pred_2025

"""Para la línea 1 encontramos una media de 398,984 y una mediana de 453,625,con una desviación estándar de 83,897.

Para la línea 2 encontramos una media de 205,604 y una mediana de 229,834, con valores más cercanos al tercer cuartil (235,111). También tenemos una desviación estándar de 38,415.

Tienen algunos días con valores bajos, lo que reduce la media. La desviación estándar, en especial para la Línea 1, muestra la variabilidad en la afluencia,en pocas palabras la prediccion tiene un comporamiento similar a la afluencia de 2024
"""

#Grafico de caja y bigotes
# Extraer día de la semana (0=Lunes, 6=Domingo)
df_predicciones_final_linea1_2025['dia_semana'] = pd.to_datetime(df_predicciones_final_linea1_2025['fecha']).dt.dayofweek
df_predicciones_final_linea2_2025['dia_semana'] = pd.to_datetime(df_predicciones_final_linea2_2025['fecha']).dt.dayofweek

# Nombres de días para el eje X
nombres_dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']

#Grafico
plt.figure(figsize=(10, 6))

sns.boxplot(
    x='dia_semana',
    y='prediccion_afluencia_linea1_2025',
    data=df_predicciones_final_linea1_2025,
    showmeans=True,  # Media con triángulo verde
    flierprops={'marker': 'o', 'markersize': 8},  # Outliers
    width=0.6,

)

# Títulos y etiquetas
plt.title('Afluencia Predicha por dia-Linea 1 MB CDMX 2025', pad=20)
plt.xlabel('Dia de la Semana', labelpad=10)
plt.ylabel('Afluencia Predicha', labelpad=10)
plt.xticks(ticks=range(7), labels=nombres_dias, rotation=45, ha='right')

# Ajustes finales
plt.tight_layout()
plt.grid(axis='y', alpha=0.3)
plt.show()

# GRÁFICO PARA LÍNEA 2
plt.figure(figsize=(10, 6))

sns.boxplot(
    x='dia_semana',
    y='prediccion_afluencia_linea2_2025',
    data=df_predicciones_final_linea2_2025,
    showmeans=True,
    flierprops={'marker': 'o', 'markersize': 8},
    width=0.6,
)

plt.title('Afluencia Predicha por dia-Linea 2 MB CDMX 2025', pad=20)
plt.xlabel('Dia de la Semana', labelpad=10)
plt.ylabel('Afluencia  Predicha', labelpad=10)
plt.xticks(ticks=range(7), labels=nombres_dias, rotation=45, ha='right')

plt.tight_layout()
plt.grid(axis='y', alpha=0.3)
plt.show()

"""#METRICAS Y EVALUACION
La evaluacion se hara con los datos reales de febrero a abril 2025 debido a que son los disponibles al momento de elaborar el proyecto

#EVALUACION PARCIAL LINEA 1

#Cargada de datos linea 1
"""

#Datos de la afluencia de la linea 1
#datos_reales_afluencia_linea1_2025 = pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/afluenciareal2025/linea1afluenciareal2025/linea1datosreal2025.csv")
datos_reales_afluencia_linea1_2025 = pd.read_csv("linea1datosreal2025.csv")
datos_reales_afluencia_linea1_2025
datos_reales_afluencia_linea1_2025['fecha'] = pd.to_datetime(datos_reales_afluencia_linea1_2025['fecha'])
print(datos_reales_afluencia_linea1_2025.tail())

#Se aplica la funcion procesar_afluencia para unir los datos
#Linea 1
datos_reales_linea1_2025_procesado = procesar_afluencia(datos_reales_afluencia_linea1_2025)
#Se renombra la columna de afluencia total para mayor claridad
datos_reales_linea1_2025_procesado.rename(columns={'afluencia_total': 'afluenciareal_linea1'}, inplace=True)
print(datos_reales_linea1_2025_procesado.head())
print(datos_reales_linea1_2025_procesado.tail())

"""#Comparacion de los datos (predicho vs real) Linea 1 febrero-abril 2025"""

#Seleccion de los valores de febrero a abril predichos para 2025
df_feb_abr_predicho_2025_linea1 = df_predicciones_final_linea1_2025[(df_predicciones_final_linea1_2025['fecha'].dt.month >= 2) & (df_predicciones_final_linea1_2025['fecha'].dt.month <= 4)]
print(df_feb_abr_predicho_2025_linea1.tail())

# Seleccionar columnas específicas de df
columnas_predicciones = ['prediccion_afluencia_linea1_2025']
columnas_reales = ["fecha","linea","mes","anio","afluenciareal_linea1"]

# Df con las columnas que se quieren para la linea 1
def_pred_selec_linea1 = df_feb_abr_predicho_2025_linea1[columnas_predicciones]
df_real_selec_linea1 = datos_reales_linea1_2025_procesado[columnas_reales]

# Se unen horizontalmente en base a las columnas
df_unido_linea1_2025= pd.concat([ df_real_selec_linea1,def_pred_selec_linea1], axis=1)


print(df_unido_linea1_2025.head())
print(df_unido_linea1_2025.tail())

# Configuracion del grafico
plt.style.use('default')  # Estilo basico
plt.figure(figsize=(12, 6)) #Tamaño del grafico

# Gráfico de lineas para comparar la afluencia
plt.plot(df_unido_linea1_2025['fecha'],
         df_unido_linea1_2025['afluenciareal_linea1'],
         label='Afluencia real',
         color='green',
         linewidth=2)

plt.plot(df_unido_linea1_2025['fecha'],
         df_unido_linea1_2025['prediccion_afluencia_linea1_2025'],
         label='Afluencia predicha',
         color='red',
         linestyle='--',
         linewidth=2)

#Titulos
plt.title('Comparacion parcial (feb-abril 2025) Linea 1 MB CDMX', fontsize=14, pad=20)
plt.xlabel('Fecha', fontsize=12)
plt.ylabel('Afluencia', fontsize=12)
plt.xticks(rotation=45)



# Mejora la posicion
plt.legend(fontsize=12, framealpha=1, loc='upper right')

# Ajusta margenes
plt.tight_layout()

# Muestra el grafico
plt.show()

"""#Metricas para la linea 1"""

# Datos reales y predichos
real_linea1 = df_unido_linea1_2025['afluenciareal_linea1']
predicho_linea1 = df_unido_linea1_2025['prediccion_afluencia_linea1_2025']

# Cálculo de métricas
rmse = np.sqrt(mean_squared_error(real_linea1, predicho_linea1))
mae = mean_absolute_error(real_linea1, predicho_linea1)
mape = np.mean(np.abs((real_linea1[real_linea1 != 0] - predicho_linea1[real_linea1 != 0]) / real_linea1[real_linea1 != 0])) * 100

# Metricas
print("\nMétricas para Línea 1:")
print(f"- RMSE: {rmse:.2f} pasajeros")
print(f"- MAE: {mae:.2f} pasajeros")
print(f"- MAPE: {mape:.2f}%")

"""#EVALUACION PARCIAL LINEA 2

#Cargada de datos linea 2
"""

#Datos de la afluencia de la linea 1
#datos_reales_afluencia_linea2_2025 = pd.read_csv("/content/drive/My Drive/Ciencia de datos/Proyecto final/afluenciareal2025/linea2afluenciareal2025/linea2datosreal2025.csv")
datos_reales_afluencia_linea2_2025 = pd.read_csv("linea2datosreal2025.csv")
datos_reales_afluencia_linea2_2025['fecha'] = pd.to_datetime(datos_reales_afluencia_linea2_2025['fecha'])
print(datos_reales_afluencia_linea2_2025.tail())

#Se aplica la funcion procesar_afluencia para unir los datos
#Linea 2
datos_reales_linea2_2025_procesado = procesar_afluencia(datos_reales_afluencia_linea2_2025)
#Se renombra la columna de afluencia total para mayor claridad
datos_reales_linea2_2025_procesado.rename(columns={'afluencia_total': 'afluenciareal_linea2'}, inplace=True)
print(datos_reales_linea2_2025_procesado.head())
print(datos_reales_linea1_2025_procesado.tail())

"""#Comparacion de los datos (predicho vs real) Linea 2 febrero-abril 2025"""

#Seleccion de los valores de febrero a abril predichos para 2025
df_feb_abr_predicho_2025_linea2= df_predicciones_final_linea2_2025[(df_predicciones_final_linea2_2025['fecha'].dt.month >= 2) & (df_predicciones_final_linea2_2025['fecha'].dt.month <= 4)]
print(df_feb_abr_predicho_2025_linea2.head())
print(df_feb_abr_predicho_2025_linea2.tail())

# Seleccionar columnas específicas de df
col_predic_linea2_2025 = ['prediccion_afluencia_linea2_2025']  # Reemplaza con las columnas que quieres del df_predicciones
columnas_reales_linea2_2025 = ["fecha","linea","mes","anio","afluenciareal_linea2"]        # Reemplaza con las columnas que quieres del df_reales

# Df con las columnas que se quieren para la linea 2
def_pred_selec_linea2 = df_feb_abr_predicho_2025_linea2[col_predic_linea2_2025]
df_real_selec_linea2 = datos_reales_linea2_2025_procesado[columnas_reales_linea2_2025]

# Se unen horizontalmente en base a las columnas
df_unido_linea2_2025= pd.concat([ df_real_selec_linea2,def_pred_selec_linea2], axis=1)


print(df_unido_linea2_2025.head())
print(df_unido_linea2_2025.tail())
print(df_unido_linea2_2025.columns)

# Configuracion del grafico
plt.style.use('default')  # Estilo basico
plt.figure(figsize=(12, 6)) #Tamaño del grafico

# Gráfico de lineas para comparar la afluencia
plt.plot(df_unido_linea2_2025['fecha'],
         df_unido_linea2_2025['afluenciareal_linea2'],
         label='Afluencia real',
         color='green',
         linewidth=2)

plt.plot(df_unido_linea2_2025['fecha'],
         df_unido_linea2_2025['prediccion_afluencia_linea2_2025'],
         label='Afluencia predicha',
         color='red',
         linestyle='--',
         linewidth=2)

#Titulos
plt.title('Comparacion parcial (feb-abril 2025) Linea 2 MB CDMX', fontsize=14, pad=20)
plt.xlabel('Fecha', fontsize=12)
plt.ylabel('Afluencia', fontsize=12)
plt.xticks(rotation=45)



# Mejora la posicion
plt.legend(fontsize=12, framealpha=1, loc='upper right')

# Ajusta margenes
plt.tight_layout()

# Muestra el grafico
plt.show()

"""#Metricas para la linea 2"""

# Datos reales y predichos para la linea 2
real_linea2 = df_unido_linea2_2025['afluenciareal_linea2']
predicho_linea2 = df_unido_linea2_2025['prediccion_afluencia_linea2_2025']

# Cálculo de métricas
rmse = np.sqrt(mean_squared_error(real_linea2, predicho_linea2))
mae = mean_absolute_error(real_linea2, predicho_linea2)
mape = np.mean(np.abs((real_linea2[real_linea2 != 0] - predicho_linea2[real_linea2 != 0]) / real_linea2[real_linea2 != 0])) * 100

#Metricas
print("\nMétricas para Línea 2:")
print(f"- RMSE: {rmse:.2f} pasajeros")
print(f"- MAE: {mae:.2f} pasajeros")
print(f"- MAPE: {mape:.2f}%")